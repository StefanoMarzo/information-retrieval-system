{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb534a5",
   "metadata": {},
   "source": [
    "<h2>Indexing the document collection</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453a7cce",
   "metadata": {},
   "source": [
    "<h3>Settings & utilities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a21f59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import spacy #lemmatization\n",
    "import pickle #serialize object read/write files\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc7d6b",
   "metadata": {},
   "source": [
    "<h3>Load document collection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68faeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the document collection\n",
    "collection_path = 'C:/Users/Stefano Marzo/Documents/DCU Master Dublin/05 Second semester modules/CA6005 Mechanics of search/01 Assignment/COLLECTION'\n",
    "\n",
    "def getDocumentList(path):\n",
    "    return os.listdir(path)\n",
    "    \n",
    "#generate document name list\n",
    "doc_list = getDocumentList(collection_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f123fb",
   "metadata": {},
   "source": [
    "<h3>Load queries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab34d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_path = 'C:/Users/Stefano Marzo/Documents/DCU Master Dublin/05 Second semester modules/CA6005 Mechanics of search/01 Assignment/topics'\n",
    "\n",
    "#generate query name list\n",
    "queries_list = getDocumentList(queries_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac66692",
   "metadata": {},
   "source": [
    "<h3>Utilities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce6e0c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideList(list_in, percentage, seed):\n",
    "    if percentage < 0 or percentage > 1:\n",
    "        print('Percentage must be between 0 and 1')\n",
    "        return []\n",
    "    np.random.seed(seed)\n",
    "    idx = np.random.shuffle(list_in)\n",
    "    if percentage == 1:\n",
    "        return list_in\n",
    "    i = round(len(list_in) * percentage)\n",
    "    return list_in[0:i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f24fe",
   "metadata": {},
   "source": [
    "<h2>Processing text</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a2853e",
   "metadata": {},
   "source": [
    "<h3>Load stopwords</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ef99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a stopword list NLTK\n",
    "gist_file = open(\"stopwords.txt\", \"r\")\n",
    "try:\n",
    "    content = gist_file.read()\n",
    "    stopwords = content.split(\",\")\n",
    "finally:\n",
    "    gist_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930b89f",
   "metadata": {},
   "source": [
    "<h3>Text Processing Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55e7c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process text to meet the IR requirements\n",
    "use_lemmatization = True\n",
    "\n",
    "# Lemmatization\n",
    "# https://www.analyticsvidhya.com/blog/2019/08\n",
    "#/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python\n",
    "#/?utm_source=blog&utm_medium=information-retrieval-using-word2vec-based-vector-space-model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['ner','parser'])\n",
    "nlp.max_length=5000000\n",
    "\n",
    "def lemmatize(x):\n",
    "    return ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)])\n",
    "    \n",
    "    \n",
    "#Returns a list of relevant terms\n",
    "def processText(text):\n",
    "    #remove punctuation and stopwords\n",
    "    #remove single punctuation characters, remove points (not separated from string), lower case all \n",
    "    if not isinstance(text, str) :\n",
    "        return []\n",
    "    #remove punctuation\n",
    "    text = text.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))).strip()\n",
    "    #remove unnecessary whitespace\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    #lower the text\n",
    "    text = text.lower()\n",
    "    #lemmatize\n",
    "    if use_lemmatization:\n",
    "        text = lemmatize(text)\n",
    "    return list(filter(lambda el: el not in stopwords, text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7d5697",
   "metadata": {},
   "source": [
    "<h2>Class for XML documents</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0344e74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XmlFile:\n",
    "    def __init__(self, xml, xml_id, field_dict, processText):\n",
    "        self.field_dict = field_dict\n",
    "        tree = ET.parse(xml)\n",
    "        root = tree.getroot()\n",
    "        for id in root.iter(xml_id):\n",
    "            self.id = id.text if id.text is not None else ''\n",
    "        for xml_name, field_name in field_dict.items():\n",
    "            for content in root.iter(xml_name):\n",
    "                self.__dict__[field_name] = processText(content.text) if content.text is not None else []\n",
    "                \n",
    "    def __getTF__(self, processed_text):\n",
    "        #f/max_occurance of most frequent term\n",
    "        num_terms = len(processed_text)\n",
    "        tf_index = {}\n",
    "        max_term_count = 0\n",
    "        for term in processed_text:\n",
    "            if term not in tf_index: #save some time\n",
    "                term_count = processed_text.count(term)\n",
    "                if term_count > max_term_count:\n",
    "                    max_term_count = term_count\n",
    "                tf_index[term] = term_count/num_terms\n",
    "        #Normalization does not affect the results in this collection\n",
    "        #for term in tf_index.keys():\n",
    "            #tf_index[term] = tf_index[term] / max_term_count\n",
    "        return tf_index\n",
    "    \n",
    "    def getWeightedTf(self, term, weight_list):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2aeac326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant document tags \n",
    "xml_doc_id = 'DOCID'\n",
    "xml_doc_fields = {'HEADLINE' : 'processed_head', \n",
    "                'TEXT' : 'processed_body'}\n",
    "\n",
    "class XmlDoc(XmlFile):\n",
    "    def __init__(self, xml):\n",
    "        super().__init__(xml, xml_doc_id, xml_doc_fields, processText)       \n",
    "        self.tf_head = self.__getTF__(self.processed_head)\n",
    "        self.tf_body = self.__getTF__(self.processed_body)\n",
    "        self.tf_text = self.__getTF__(self.processed_head + self.processed_body)\n",
    "    \n",
    "    def getWeightedTf(self, term, w_head=1, w_body=1):\n",
    "        try:\n",
    "            tf_body = self.tf_body[term] * w_body\n",
    "        except:\n",
    "            tf_body = 0\n",
    "        try:\n",
    "            tf_head = self.tf_head[term] * w_head\n",
    "        except:\n",
    "            tf_head = 0\n",
    "        return tf_body + tf_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd3a09a",
   "metadata": {},
   "source": [
    "<h2>Document Collection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea6fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentCollection:\n",
    "    def __init__(self, path, doc_list, \n",
    "                 model_structure_file_path = 'model_structures/'\n",
    "                ):\n",
    "        self.docs_filename = model_structure_file_path+'document_collection.docs'\n",
    "        self.index_filename = model_structure_file_path+'document_collection.inverted_index'\n",
    "        self.global_ft_filename = model_structure_file_path+'document_collection.global_tf'\n",
    "        self.total_terms_in_collection_filename = model_structure_file_path+'document_collection.total_terms_in_collection'\n",
    "        self.idf_filename = model_structure_file_path+'document_collection.idf'\n",
    "        self.avgdl_filename = model_structure_file_path+'document_collection.avgdl'\n",
    "        self.path = path\n",
    "        self.division_factor = 4\n",
    "        #Inverted index \n",
    "            \n",
    "    def loadFromFile(self):\n",
    "        #Docs\n",
    "        self.docs = {}\n",
    "        for i in range(self.division_factor):\n",
    "            with open(self.docs_filename+'.part_'+str(i), 'rb') as dictionary_file:\n",
    "                self.docs.update(pickle.load(dictionary_file))\n",
    "        #Inverted Index\n",
    "        with open(self.index_filename, 'rb') as dictionary_file:\n",
    "            self.inverted_index = pickle.load(dictionary_file)\n",
    "        #Global TF\n",
    "        with open(self.global_ft_filename, 'rb') as dictionary_file:\n",
    "            self.global_tf = pickle.load(dictionary_file)\n",
    "        #Idf\n",
    "        with open(self.idf_filename, 'rb') as dictionary_file:\n",
    "            self.idf = pickle.load(dictionary_file)\n",
    "        #total terms in collection\n",
    "        with open(self.total_terms_in_collection_filename, 'rb') as dictionary_file:\n",
    "            self.total_terms_in_collection = pickle.load(dictionary_file)\n",
    "        #Avg Doc Length\n",
    "        with open(self.avgdl_filename, 'rb') as dictionary_file:\n",
    "            self.avgdl = pickle.load(dictionary_file)\n",
    "    \n",
    "    def computeAndDump(self, doc_list):\n",
    "        division_lenght = round(len(doc_list)/self.division_factor)\n",
    "        #Docs\n",
    "        self.docs = {}\n",
    "        for i in range(self.division_factor):\n",
    "            docs = {}\n",
    "            st = i*division_lenght\n",
    "            en = (i+1)*division_lenght\n",
    "            for d in doc_list[st:en]:\n",
    "                xml_document = XmlDoc(self.path + '/' + d)\n",
    "                docs[xml_document.id] = xml_document\n",
    "            with open(self.docs_filename+'.part_'+str(i), 'wb') as dictionary_file:\n",
    "                pickle.dump(docs, dictionary_file)\n",
    "            self.docs.update(docs)\n",
    "        \n",
    "        self.global_tf = {}\n",
    "        self.total_terms_in_collection = 0\n",
    "        self.inverted_index = {}\n",
    "        for id in self.docs.keys():\n",
    "            for term in self.docs[id].processed_head + self.docs[id].processed_body:\n",
    "                self.total_terms_in_collection += 1\n",
    "                if term not in self.global_tf:\n",
    "                    self.global_tf[term] = 1\n",
    "                else: self.global_tf[term] += 1\n",
    "                if term in self.inverted_index:\n",
    "                    self.inverted_index[term].add(id)\n",
    "                else: self.inverted_index[term] = {id}\n",
    "        for term in self.global_tf.keys():\n",
    "            self.global_tf[term] = self.global_tf[term] / self.total_terms_in_collection\n",
    "        \n",
    "        #Table of IDF\n",
    "        self.idf = {}\n",
    "        for term in self.inverted_index.keys():\n",
    "            self.idf[term] = np.log(len(self.docs) / len(self.inverted_index[term]))\n",
    "            \n",
    "        #Average document length\n",
    "        self.avgdl = np.mean([len(item.processed_head + item.processed_body) for k, item in self.docs.items()])\n",
    "        \n",
    "        with open(self.index_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.inverted_index, dictionary_file)\n",
    "            \n",
    "        with open(self.global_ft_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.global_tf, dictionary_file)\n",
    "            \n",
    "        with open(self.idf_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.idf, dictionary_file)\n",
    "            \n",
    "        with open(self.total_terms_in_collection_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.total_terms_in_collection, dictionary_file)\n",
    "            \n",
    "        with open(self.avgdl_filename, 'wb') as dictionary_file:\n",
    "            pickle.dump(self.avgdl, dictionary_file)\n",
    "        \n",
    "    \n",
    "    def getRelevance(self, document_id, term):\n",
    "        try:\n",
    "            return self.docs[document_id].tf_text[term] * self.idf[term]\n",
    "        except: \n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def getRelevanceBody(self, document_id, term):\n",
    "        try:\n",
    "            return self.docs[document_id].tf_body[term] * self.idf[term]\n",
    "        except: \n",
    "            return 0\n",
    "        \n",
    "    def getRelevanceHead(self, document_id, term):\n",
    "        try:\n",
    "            return self.docs[document_id].tf_headline[term] * self.idf[term]\n",
    "        except: \n",
    "            return 0\n",
    "        \n",
    "    def getWeightedRelevance(self, document_id, term, w_head=1, w_body=1):\n",
    "        try:\n",
    "            return self.docs[document_id].getWeightedTf(term, w_head, w_body) * self.idf[term]\n",
    "        except:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcda5e8",
   "metadata": {},
   "source": [
    "<h2>Classes for handle XML queries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41a6565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant query tags \n",
    "xml_query_id = 'QUERYID'\n",
    "xml_query_fields = {'TITLE' : 'processed_text'}\n",
    "\n",
    "class XmlQuery(XmlFile):\n",
    "    def __init__(self, xml):\n",
    "        super().__init__(xml, xml_query_id, xml_query_fields, processText)\n",
    "        #self.tf_index = self.__getTF__(self.processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf37bf",
   "metadata": {},
   "source": [
    "<h2>Query collection</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b4730d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryCollection:\n",
    "    def __init__(self, path, query_list, filename='model_structures/query-collection.dictionary'):\n",
    "        #List of XmlQuery object\n",
    "        self.queries = {}\n",
    "        for d in query_list:\n",
    "            xml_query = XmlQuery(path + '/' + d)\n",
    "            self.queries[xml_query.id] = xml_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1164573a",
   "metadata": {},
   "source": [
    "<h2>Create Document Collection and Query Collection objects</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4dea647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Collection Loaded in 4.7733s\n",
      "Query Collection Computed in 0.728s\n"
     ]
    }
   ],
   "source": [
    "recompute_all = False\n",
    "#seed for random number\n",
    "seed = 1\n",
    "doc_list = getDocumentList(collection_path)\n",
    "queries_list = getDocumentList(queries_path)\n",
    "#divide the document collection (get pd% of documents)\n",
    "pd = 1\n",
    "doc_list = divideList(doc_list, pd, seed)\n",
    "\n",
    "#divide the query collection (get pq% of documents)\n",
    "pq = 1\n",
    "queries_list = divideList(queries_list, pq, seed)\n",
    "\n",
    "#Compute or read document collection\n",
    "compute_document_collection = False or recompute_all\n",
    "\n",
    "#create a Document collection object\n",
    "document_collection = DocumentCollection(collection_path, doc_list)\n",
    "if compute_document_collection:\n",
    "    start = time.time()\n",
    "    document_collection.computeAndDump(doc_list)\n",
    "    end = time.time()\n",
    "    print('Document Collection Computed in ' + str(round(end - start, 4)) + 's')\n",
    "else:\n",
    "    start = time.time()\n",
    "    document_collection.loadFromFile()\n",
    "    end = time.time()\n",
    "    print('Document Collection Loaded in ' + str(round(end - start, 4)) + 's')\n",
    "\n",
    "#Compute or read query collection\n",
    "compute_query_collection = True or recompute_all\n",
    "query_collection_filename = 'model_structures/query-collection.dictionary'\n",
    "\n",
    "#create a Query collection object\n",
    "if compute_query_collection or not os.path.isfile(query_collection_filename):\n",
    "    start = time.time()\n",
    "    query_collection = QueryCollection(queries_path, queries_list, query_collection_filename)\n",
    "    end = time.time()\n",
    "    print('Query Collection Computed in ' + str(round(end - start, 4)) + 's')\n",
    "else:\n",
    "    start = time.time()\n",
    "    with open(query_collection_filename, 'rb') as dictionary_file:\n",
    "        query_collection = pickle.load(dictionary_file) \n",
    "    end = time.time()\n",
    "    print('Query Collection Loaded in ' + str(round(end - start, 4)) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da9be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankResult:\n",
    "    def __init__(self, q_id, d_id, relevance):\n",
    "        self.q_id = q_id\n",
    "        self.d_id = d_id\n",
    "        self.relevance = relevance\n",
    "        \n",
    "class RankingModel:\n",
    "    def __init__(self, document_collection, query_collection, \n",
    "                 track_id='-', run_id='Rank', out_path='IR_output/'):\n",
    "        self.document_collection = document_collection\n",
    "        self.query_collection = query_collection\n",
    "        self.track_id = track_id\n",
    "        self.run_id = run_id\n",
    "        self.out_path = out_path\n",
    "    \n",
    "    def getQueryResult(self, query, limit_result):\n",
    "        rank = []\n",
    "        search_space = set()\n",
    "        for term in query.processed_text:\n",
    "            if term in self.document_collection.inverted_index:\n",
    "                search_space = search_space.union(set(self.document_collection.inverted_index[term]))\n",
    "        for doc_id in search_space:\n",
    "            rank += [RankResult(query.id, doc_id, self.calculateRelevance(self.document_collection.docs[doc_id], query))] \n",
    "        rank.sort(key=lambda x: x.relevance, reverse=True)\n",
    "        res = ''\n",
    "        for i in range(len(rank[0:limit_result])):\n",
    "            res += rank[i].q_id + ' ' + self.track_id + ' ' + rank[i].d_id + ' ' + str(i) + ' ' + str(rank[i].relevance) + ' ' + self.run_id + '\\n'\n",
    "        return res\n",
    "    \n",
    "    def getReport(self, out_folder = 'Rank/', limit_result = 1000, model_name='Rank'):\n",
    "        file = open(self.out_path + out_folder + self.run_id + \".out\", \"w\")\n",
    "        start = time.time()\n",
    "        for q in self.query_collection.queries.keys():\n",
    "            file.write(self.getQueryResult(self.query_collection.queries[q], limit_result))\n",
    "        end = time.time()\n",
    "        print(model_name + ' Ranking Computation time: ' + str(round(end-start, 4)) + 's')\n",
    "        file.close()\n",
    "    \n",
    "    def calculateRelevance(self, document, query):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21feb291",
   "metadata": {},
   "source": [
    "<h2>Vector space model VSM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a17c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSpaceModel(RankingModel):\n",
    "    def __init__(self, document_collection, query_collection, \n",
    "                 run_id='VSM', track_id='-'\n",
    "                ):\n",
    "        super().__init__(document_collection, query_collection, track_id, run_id)\n",
    "        \n",
    "    \n",
    "    def vectorizeXmlQuery(self, xml_query):\n",
    "        return [self.getQueryRelevance(xml_query, t) for t in xml_query.processed_text]\n",
    "    \n",
    "    def vectorizeDocument(self, document, query):\n",
    "        return [self.getDocumentRelevance(document, t) for t in query.processed_text]\n",
    "\n",
    "    #tf-idf\n",
    "    def getDocumentRelevance(self, document, term):\n",
    "        return self.document_collection.getRelevance(document.id, term)\n",
    "    def getQueryRelevance(self, query, term):\n",
    "        return query.processed_text.count(term)/len(query.processed_text)\n",
    "    \n",
    "    def cosineSimilarity(self, vect1, vect2):\n",
    "        norm1 = np.linalg.norm(vect1)\n",
    "        norm2 = np.linalg.norm(vect2)\n",
    "        dot_p = np.dot(vect1, vect2)\n",
    "        #origin vector is equal to itself\n",
    "        if dot_p == 0 and norm1 == 0 and norm2 == 0:\n",
    "            return 1\n",
    "        #origin vector is not equal to any vector but itself\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            return 0\n",
    "        return dot_p / (norm1 * norm2)\n",
    "\n",
    "    def dotSimilarity(self, vect1, vect2):\n",
    "        return np.dot(vect1, vect2)\n",
    "    \n",
    "    def calculateRelevance(self, document, query, similarity_function=lambda v1, v2: np.dot(v1, v2)):\n",
    "        v_query = self.vectorizeXmlQuery(query)\n",
    "        v_doc = self.vectorizeDocument(document, query)        \n",
    "        return similarity_function(v_doc, v_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f8d93b",
   "metadata": {},
   "source": [
    "<h2>Generate the VSM report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af06cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VSM Ranking Computation time: 6.2038s\n"
     ]
    }
   ],
   "source": [
    "vsm = VectorSpaceModel(document_collection, query_collection)\n",
    "vsm.getReport(out_folder = 'VSM/', limit_result = 1000, model_name='VSM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0d027",
   "metadata": {},
   "source": [
    "<h2>BM25 ranking</h2>\n",
    "<p>For a query $Q$ and a term $t \\in Q$, the <b>BM25</b> score for a document $D$ is: </p>\n",
    "<h1>$Relevance(D,t) = IDF(t) \\cdot \\frac{count(D, t) \\cdot (k + 1)}{count(D, t) + k \\cdot (1 - b + \\frac{b|D|}{avgdl})} $</h1>\n",
    "<p>Where $count(D, t)$ is the number of occurrencies of $t$ in $D$</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff3d6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25(VectorSpaceModel):\n",
    "    def __init__(self, \n",
    "                 document_collection, \n",
    "                 query_collection, \n",
    "                 k = 1.2, \n",
    "                 b = .75,\n",
    "                 track_id = '-', \n",
    "                 run_id='BM25'                 \n",
    "                ):\n",
    "        super().__init__(document_collection, query_collection, track_id=track_id, run_id=run_id)\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "    \n",
    "    def getDocumentRelevance(self, document, term):\n",
    "        try:\n",
    "            idf_term = self.document_collection.idf[term]\n",
    "            #x = number of occurencies of term in document\n",
    "            x = document.tf_text[term] * len(document.processed_body+document.processed_head)\n",
    "        except:\n",
    "            return 0\n",
    "        doc_len = len(document.processed_head + document.processed_body)\n",
    "        normalizer = 1 - self.b + (self.b * doc_len / self.document_collection.avgdl)\n",
    "        return (self.k + 1) * x / (x + self.k * normalizer) * idf_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7310ba41",
   "metadata": {},
   "source": [
    "<h2>Generate the BM25 report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9be4341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 Ranking Computation time: 10.6581s\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25(document_collection, query_collection)\n",
    "bm25.getReport(out_folder = 'BM25/', limit_result = 1000, model_name='BM25')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689cebae",
   "metadata": {},
   "source": [
    "<h2>BM25F</h2>\n",
    "<p>Attributing different relevance with respect to the document field</p>\n",
    "<h2>$BM25F = \\sum_{i=1}^{n}IDF(q_i) \\cdot \\frac{tf(D, q_i) \\cdot (k + 1)}{tf(D, q_i) + k \\cdot (1 - b - \\frac{b|D|}{avgdl})}$</h2>\n",
    "<p>Where</p>\n",
    "<h2>$tf(D, q_i) = \\sum_{c \\in D} w_c \\cdot tf_c(D, q_i)$</h2>\n",
    "<p>and</p>\n",
    "<ul>\n",
    "    <li>$c$ is a document field</li>\n",
    "    <li>$w_c$ is the weight attributed to field c</li>\n",
    "    <li>$tf_c(D, q_i)$ is the term frequency for the field $c$ </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c413d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25F(VectorSpaceModel):\n",
    "    def __init__(self, document_collection, query_collection, k=1.2, b=.75, track_id='-', run_id='BM25F',\n",
    "                w_head=3, w_body=1):\n",
    "        super().__init__(document_collection, query_collection, track_id=track_id, run_id=run_id)\n",
    "        self.w_head = w_head\n",
    "        self.w_body = w_body\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "    \n",
    "    def getDocumentRelevance(self, document, term):\n",
    "        try:\n",
    "            idf_term = self.document_collection.idf[term]\n",
    "        except:\n",
    "            return 0\n",
    "        x_head = document.tf_head[term] * len(document.processed_head) * self.w_head if term in document.tf_head else 0\n",
    "        x_body = document.tf_body[term] * len(document.processed_body) * self.w_body if term in document.tf_body else 0\n",
    "        x = x_head + x_body\n",
    "        \n",
    "        doc_len = len(document.processed_head + document.processed_body)\n",
    "        normalizer = 1 - self.b + (self.b * doc_len / self.document_collection.avgdl)\n",
    "        return (self.k + 1) * x / (x + self.k * normalizer) * idf_term\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b575c",
   "metadata": {},
   "source": [
    "<h2>Generate the BM25F report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a22a48c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25F Ranking Computation time: 12.3722s\n"
     ]
    }
   ],
   "source": [
    "bm25f = BM25F(document_collection, query_collection, w_head=3, w_body=1)\n",
    "bm25f.getReport(out_folder = 'BM25F/', limit_result = 1000, model_name='BM25F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece115c8",
   "metadata": {},
   "source": [
    "<h2>Unigram Language Model</h2>\n",
    "<p>A unigram language model does not consider the context and estimates each term independently. \n",
    "    As a result:\n",
    "    $P_{uni}(t_1 t_2 t_3 t_4) = P(t_1)P(t_2)P(t_3)P(t_4)$\n",
    "</p>\n",
    "\n",
    "<p>It is possible to consider a document $d$ as a generative model $M_d$ s.t. $\\sum_{t}P(t|M_d) = 1$</p>\n",
    "<p>Given a query $q$ we rank documents exploiting the likelihood of the document model to generate $q: P(q|M_d)$.</p>\n",
    "<p><b>Maximum likelihood estimate (MLE)</b> for a query $q = [t_1, \\dots, t_n]$ and a generative model $M_d$, $P(t_1, \\dots, t_n | M_d) = tf(d, t_1) \\times \\dots \\times tf(d, t_n)$</p>\n",
    "<p><b>Zero Probability Problem: </b>if a term $t_h \\in q$ is s.t. $tf(d, t_h) = 0$ hence $P(q|M_d) = 0$</p>\n",
    "<p>To overcome this problem, only query term that are present in the document will be attributed a probability, the probability of the total seen terms is normalized to $1$</p>\n",
    "<p><b>Over Estimation Problem: </b> since with MLE only terms belonging to $q \\cap d$ are estimated, if there is only one common term between document and query, i.e. $|q \\cap d| = 1$, the relevance would be $1$</p>\n",
    "<p>To overcome this second problem, it is common to attribute a mass weight to other terms in the document i.e. <b>smoothing</b>.</p>\n",
    "<p><b>Linear smoothing: </b> given a document model $M_d$ and a collection model $M_c$:</p>\n",
    "<h2>$P(t|M_d) = \\lambda \\frac{tf(d, t)}{|d|} + (1 - \\lambda) P(t|M_c)$</h2>\n",
    "<p>where $\\lambda$ is a parameter s.t. $\\lambda \\in (0, 1)$ and $P(t|M_c)$ is the term frequency of $t$ in the entire collection of documents</p>\n",
    "<p>Note: for high values of $\\lambda$ the search is more <i>conjunctive</i> i.e. favour documents containing all query terms, for low values of $\\lambda$ the search is more <i>disjunctive</i> i.e. more suitable for long queries. Tuning this parameter is collection-specific.</p>\n",
    "<p><b>Dirichlet Smoothing: </b>more effective in IR, sets <font size=\"+2\">$\\lambda = \\frac{|d|}{\\alpha + |d|}$</font> where $\\alpha$ is the background mass i.e. the number of terms not in $q \\cap d$</p>\n",
    "<p>Finally: </p>\n",
    "<h2>$P(q|d) = \\prod_{t \\in q} (\\lambda \\frac{tf(d,t)}{|d|} + (1-\\lambda) \\frac{tf(c, t)}{|c|}) = $</h2>\n",
    "<h2>$\\prod_{t \\in q} (\\frac{|d|}{\\alpha + |d|} \\frac{tf(d,t)}{|d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|}) = \\prod_{t \\in q} ( \\frac{tf(d,t)}{\\alpha + |d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|})$</h2>\n",
    "<p>Using logs to avoid underflow in computation since $log(xy) = log(x) + log(y)$: </p>\n",
    "<h2>$log(P(q|d)) = \\sum_{t \\in q} log( \\frac{tf(d,t)}{\\alpha + |d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|})$</h2>\n",
    "<p><b>Problem: </b>if a term $t$ is not present in the entire document collection, ranking of documents would be $- \\infty$, if <font size=\"+1\">$(\\frac{tf(d,t)}{\\alpha + |d|} + \\frac{\\alpha}{\\alpha + |d|} \\frac{tf(c, t)}{|c|}) = 0$</font> for a term $t$ that term will not be considered</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0502145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramLanguageModel(RankingModel):\n",
    "    def __init__(self, document_collection, query_collection, track_id='-', run_id='ULM'):\n",
    "        super().__init__(document_collection, query_collection, track_id, run_id)\n",
    "    \n",
    "    def calculateRelevance(self, document, query):\n",
    "        relevance = 0\n",
    "        d_len = len(document.processed_head + document.processed_body)\n",
    "        alpha = len([t for t in document.processed_head + document.processed_body if t not in query.processed_text])\n",
    "        for t in query.processed_text:\n",
    "            #must multiply * d_len because of the tf_text formulation in XmlDocument class\n",
    "            first_term = document.tf_text[t] * d_len if t in document.tf_text else 0\n",
    "            second_term = alpha * self.document_collection.global_tf[t] if t in self.document_collection.global_tf else 0#global_tf includes |c|\n",
    "            denumerator = (d_len + alpha)\n",
    "            result = (first_term + second_term) / denumerator\n",
    "            relevance += np.log(result) if result != 0 else 0 #if a term in a query is not present in entire document collection, relevance is -inf\n",
    "        return relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089d7bf5",
   "metadata": {},
   "source": [
    "<h2>Generate the ULM report for trec_eval</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cb7e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ULM Ranking Computation time: 38.6657s\n"
     ]
    }
   ],
   "source": [
    "ulm = UnigramLanguageModel(document_collection, query_collection)\n",
    "ulm.getReport(out_folder = 'ULM/', limit_result = 1000, model_name='ULM')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
